# 运输层参考笔记

本文是我在学习计算机网络期间做的笔记。

内容主要来自于谢希仁《计算机网络·第七版》，同时参考了*Computer Networking: A Top-Down Approach* 以及  Dr.Tanenbaum 的 *Computer Networks*。

欢迎大家转载交流，但请勿将此文用作商业用途。

[TOC]

## 一、运输层概述

### 1. 运输层提供的服务

运输层在 TCP/IP 协议栈中介于应用层和网络层之间。

网络层在主机之间提供逻辑通信，而运输层在**应用进程**之间提供**逻辑通信**。“逻辑通信”的意思是，运输层向高层用户屏蔽了下面网络核心的细节，使应用进程看起来就好像是两个运输层实体之间有一条端到端的逻辑通信信道。

视协议的不同，运输层提供的具体服务也各不相同。

### 2. 运输层的两个主要协议

根据应用程序的不同需求，运输层有两种不同的运输协议：

* 用户数据报协议 UDP（User Datagram Protocol）
* 传输控制协议 TCP（Transmission Control Protocol）

UDP 传送的数据单位称为 **UDP 用户数据报**，TCP 传送的则称为 **TCP 报文段**（segment）。

UDP 的特点是不需要先建立连接，不提供可靠交付、开销小。使用 UDP 的应用层协议有：DNS、TFTP、RIP、DHCP、SNMP、NFS 等。

TCP 则提供可靠的、面向连接的运输服务，但占用更多资源。使用 TCP 的应用层协议有：SMTP、TELNET、HTTP、FTP 等。

### 3. 复用与分用

运输层的基本责任是**将主机间交付扩展到进程间交付**，又被称为运输层的多路复用（multiplexing）与多路分解（demultiplexing）。

**多路复用**（又称复用）指的是应用层的所有应用进程都可以通过同一个运输层协议传送数据到网络层。

**多路分解**（又称分用）指的是运输层从网络层收到发送给各应用进程的数据后，分别交付指明的各应用进程。

### 4. 端口

提供进程间通信就必须首先识别终点，但进程标识符在不同操作系统中格式各不相同，而且进程的创建和撤销都是动态的，通信的一方很难识别对方机器上的具体进程。

为了**利用目的主机提供的功能**来识别终点，而不需要知道实现功能的具体进程，可以在运输层使用协议端口号，简称**端口**。它是应用层的各种协议进程与运输实体进行层间交互的一种地址。

TCP/IP 用一个 **16 位**端口号来标志一个端口。端口号**只有本地意义**，不同计算机中的相同端口号是没有关联的。两个计算机的进程要相互通信，必须首先知道对方的 IP 地址和端口号。

#### (1) 服务器端口号

##### ① 周知端口号

周知端口号（well-known port number）被 IANA 指派给最重要的一些应用程序，数值为 0~1023。

|    应用程序     | 周知端口号 |
| :---------: | :---: |
|     FTP     |  21   |
|   TELNET    |  23   |
|    SMTP     |  25   |
|     DNS     |  53   |
|    TFTP     |  69   |
|    HTTP     |  80   |
|    SNMP     |  161  |
| SNMP (trap) |  162  |
|    HTTPS    |  443  |

##### ② 登记端口号

给没有周知端口号的应用程序使用，数值 1024~49151，使用这类端口号必须在 IANA 按规定手续登记，以避免重复。

#### (2) 客户端口号

又称短暂端口号，数值 49151~65535。

这类端口号仅在客户进程运行时动态选择，是为了让运输层实体能够找到自己，通信结束后，刚才用过的端口号就不复存在。

## 二、UDP 协议

### 1. UDP 的特点

UDP 协议仅在 IP 数据报服务基础上增加了**复用分用**和**差错检测**的功能，有以下主要特色：

* UDP 是**无连接**的。
  因此减少了开销和发送数据的时延。
* UDP 使用**尽最大努力交付**，不保证可靠交付。
  因此主机不需要维持复杂的连接状态表。
* UDP 是**面向报文**的。
  对应用层交下来的报文既不合并也不拆分，而是保留报文的边界。但如果应用层选择的报文大小不合适，会降低网络层的效率。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-21/22648394.jpg)

* UDP **没有拥塞控制**。
  网络出现的拥塞不会使源主机发送速率降低。这对于实时应用很重要，但也可能会引起严重的拥塞问题。
* UDP 支持一对一、一对多、多对一、多对多交互通信。
* UDP 的可定制性很强。
  本身是一个轻量级协议，应用进程可以在不影响实时性的前提下增加一些提高可靠性的措施，如前向纠错和重传。

### 2. UDP 首部格式

用户数据报 UDP 有两个字段：数据字段和首部字段。

首部字段只有 8 个字节，由四个字段组成：

* **源端口**：需要对方回信时选用，不需要时可用全 0。
* **目的端口**：运输层从网络层收到数据报时，让 UDP 数据报通过该端口号对应的端口，送到应用进程。
* **长度**：数据报长度，最小为 8 字节（只有首部），最大为 65515 字节（由于 IP 数据报的限制）。
* **检验和**：用来检测数据报在传输中是否出错，有错丢弃。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-21/86286565.jpg)

如果报文中目的端口号不正确，就丢弃该报文，并由 ICMP 协议发送差错报文给发送方。这也是 tracert 命令的原理。

### 3. 计算检验和

UDP 之所以要提供检验和，是因为不能保证源和目的之间的所有链路都提供差错检测，作为一种保险措施。

计算检验和时，首先要在 UDP 用户数据报前临时添加 12 个字节的**伪首部**，该伪首部既不向下也不向上传递，仅用于计算。

不同于 IP 数据报检验和只检验 IP 数据报首部，UDP 检验和**把首部和数据部分一起检验**。

计算步骤如下：

1. 把全零放入检验和字段。
2. 若数据部分非偶数个字节，则要填入一个全零字节。
3. 把伪首部以及 UDP 用户数据报看成由许多 16 位的字串接而成，对这些 16 比特字的和进行反码运算，求和时任何溢出都被回卷。
4. 将结果写入检验和字段，发送数据报。
5. 接收时，将收到的 UDP 用户数据报连同伪首部一起求和。当没有错误时其结果应为全 1，否则表明有差错出现，应丢弃该数据报，并可能对应用进程发出警告。

举例说明：

![](http://oxglnwe1z.bkt.clouddn.com/17-12-21/76951442.jpg)

通俗来说，就是将所有 16 比特字加到一起，有溢出就加到末位，最后求个反码，作为检验和。到接受方后再求一次检验和，只有结果为全 1 才表示没有差错。

## 三、TCP 协议

### 1. TCP 的特点

TCP 是一个非常复杂的协议，有以下主要特色：

* TCP 是**面向连接**的。
  传送数据前必须先建立 TCP 连接，数据传送完毕后释放已建立的 TCP 连接。
* TCP 提供**可靠交付**。
  通过 TCP 传送的数据，无差错、不丢失、不重复，并且按序到达。
* 每一条 TCP 连接只能有**两个端点**。
* TCP 提供**全双工通信**。
  允许通信双方进程在任何时候都能发送数据，TCP 连接的两端都设有**发送缓存**和**接收缓存**，
  * 发送时，应用程序把数据传送给 TCP 缓存后，就可以做自己的事，TCP 会在合适的时候把数据发送出去。
  * 接收时，TCP 把收到的数据放入缓存，上层应用进程在合适的时候读取缓存中的数据。
* TCP 是**面向字节流**的。
  TCP 把应用程序交下来的数据仅看成一连串无结构的字节流，无需知道所传送的字节流的含义。
  TCP 不保证收到的数据块和发送的一致（比如进程交给发送方 10 个数据块，接收方只用 4 个数据块就把收到的字节流交付给应用程序），只能保证字节流完全一样，需要接收方应用程序有能力识别收到的字节流，把它还原成有意义的应用层数据。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-21/5486359.jpg)

> 注：实际网络中，一个 TCP 报文段包含上千个字节很常见，报文段长度与发送缓存无关，只与对方给出的**窗口值**和当前网络**拥塞程度**有关。

### 2. TCP 连接与套接字

连接是 TCP 协议软件提供的一种最基本的抽象。

TCP 连接的端点叫作**套接字**（socket），端口号拼接到 IP 地址即构成了套接字。

套接字的表示方法是**在点分十进制的 IP 地址后写上端口号，中间用冒号或逗号隔开**。例如，IP 地址是 192.3.4.5 而端口号是 80，则套接字是 (192.3.4.5: 80)。
$$
套接字 socket = (IP 地址：端口号)
$$
每一条 TCP 连接唯一地被通信两端的两个套接字确定：
$$
TCP::=\{socket_1, socket_2\}=\{ (IP_1:port_1),(IP_2:port_2)\}
$$
同一个 IP 地址可以有多个不同的 TCP 连接，同一个端口号也可以有多个不同的 TCP 连接。

> 名词 socket 还有以下含义：
>
> * 允许应用程序访问连网协议的 API，称为 socket API。
> * socket API 中的一个函数名也叫作 socket。
> * 调用 socket 函数的端点称为 socket。
> * socket 函数的返回值称为 socket 描述符，简称 socket。
> * 操作系统内核中连网协议的 Berkeley 实现，称 socket 实现。

### 3. 可靠传输原理

理想传输条件：

* 传输信道无差错。
* 无论发送方以多块速度发送数据，接收方都来得及处理收到的数据。

实际网络不具备以上条件，但通过协议仍可以**在不可靠的传输网络上实现可靠传输**。

#### （1）停止等待协议

“停止等待”就是**每发送完一个分组就停止发送，等待对方确认**。

这种协议的优点是简单，缺点是信道利用率极低。

##### ① 无差错情况

A 发送分组 $M_1$，发完就暂停发送，等待 B 确认。B 收到 $M_1$ 就向 A 发送确认，A 收到确认后再发送下一个分组 $M_2$。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-21/47462755.jpg)

##### ② 出现差错

B 接收 $M_1$ 时检测出差错，就直接丢弃。A 超过一段时间没有收到确认就认为分组丢失了，重传刚才的分组。

为实现**超时重传**，每发送完一个分组就要设置一个超时计时器。

* A 发送完一个分组后，必须暂时保留其副本直到收到确认。
* 分组和确认分组都要编号，以实现对应。
* 重传时间应当比数据分组传输平均往返时间长一点（太长则效率低，太短则导致不必要的重传）。

##### ③ 确认丢失和确认迟到

![](http://oxglnwe1z.bkt.clouddn.com/17-12-21/31181042.jpg)

若 B 发送的对 $M_1$ 的确认丢失，A 在超时计时器到期后重传 $M_1$。B 再次收到 $M_1$，需采取以下行动：

1. 丢弃重复的分组 $M_1$，不向上交付。
2. 向 A 再次发送确认。

若 B 发送的确认迟到，A 收到重复的确认，就直接丢弃。B 收到重复的分组，依旧按上述规则重传确认。

由于重传请求是自动进行的，这类可靠传输协议又被称为**自动重传请求 ARQ** (Automatic Repeat reQuest)。

#### （2）连续 ARQ 协议

为提高传输效率，发送方可以采用**流水线传输**，即连续发送多个分组，不需要每发送一个分组就停下来等待确认。

这里只给出连续 ARQ 协议最基本的概念，不涉及过多细节。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-22/33024657.jpg)

上图表示发送方维持的**发送窗口**。位于发送窗口内的 5 个分组都可以连续发送出去，而不需要等待对方的确认。发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。

接收方一般采用**累积确认**的方式，即接收方不必对每个收到的分组都发送确认，而是在收到几个分组后，对按序到达的最后一个分组发送确认，表示到此分组位置的所有分组都已被正确收到。

通信线路质量不好时，连续 ARQ 协议会带来负面影响，如果几个分组中间某个分组丢失，接收方只能对前几个分组发出确认，发送方必须重传后面的所有分组，称为 **Go-back-N**。

### 4. TCP 首部格式

一个 TCP 报文段分为**首部**和**数据**两部分，首部体现了 TCP 的全部工作原理。

TCP 报文段首部的前 20 个字节是固定的，后面 4n 个字节是根据需要而增加的可选项。因此，首部最小长度是 20 字节。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-22/20762460.jpg)

* **源端口**和**目的端口**
  各占 2 字节，分别写入源端口号和目的端口号，用于实现  TCP 分用。
* **序号**
  占 4 字节，范围是 $[0, 2^{32}-1]$，共 $2^{32}$个序号。序号使用 $mod\,2^{32}$ 运算，增加到顶后，下个序号又回到 0。
  TCP 连接中传送的字节流中的每一个字节都按顺序编号。首部中的序号字段值指的是**本报文段所发送数据的第一个字节的序号**。
* **确认号**
  占 4 字节。是**期望收到对方下一个报文段的第一个数据字节的序号**。若确认号为 N，则表明到序号 N-1 为止的所有数据都已正确收到。
* **数据偏移**
  占 4 位。描述 **TCP 报文段首部长度**。数据偏移的单位是 32 位字（4 个字节），由于 4 位二进制数能表示的最大数字是 15，因此数据偏移最大值是 60 字节，即选项长度不超过 40 字节。
* **保留**
  占 6 位，保留给今后使用，但目前设置为 0。
* **控制位**
  占 6 位，用来说明本报文段的性质。
  * **紧急 URG**
    当 URG = 1 时，表明紧急指针字段有效，说明此报文段中有紧急数据，要以高优先级传送（把紧急数据插入到报文段的最前面），即使窗口为 0，也能传紧急数据。
  * **确认 ACK**
    仅当 ACK = 1 时，确认号字段才有效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。
  * **推送 PSH**（很少用）
    当应用进程希望立即得到对方响应时，可以把 PSH 置 1，并立即创建一个报文段发送出去，接受方 TCP 收到 PSH = 1 的报文段，就尽快交付应用进程，而不再等到整个缓存都填满才向上交付。
  * **复位 RST**
    TCP 连接出现严重差错时，RST 置 1，然后释放旧连接，重新建立新的 TCP 连接。
  * **同步 SYN**
    在连接建立时用来同步序号，SYN 置 1 表示这是一个连接请求或连接接受报文。当 SYN = 1 而 ACK = 0 时，表明这是一个连接请求报文段，对方若同意连接，则在响应报文段中使 SYN = 1 和 ACK = 1。
  * **终止 FIN**
    释放连接。当 FIN = 1 时，表明此报文段的发送方数据已发送完毕，要求释放运输连接。
* **窗口**
  占 2 字节，是 $[0, 2^{16}-1]$之间的整数。
  窗口指的是发送本报文段的一方的接收窗口，接收方的数据缓存空间是有限的，窗口值告诉对方：从本报文段首部的确认号算起，接收方**目前**允许对方发送的数据量，作为依据便于发送方设置其发送窗口。
* **检验和**
  占 2 字节。和 UDP 一样，都要检验首部和数据，且要加上12 字节的伪首部，区别是伪首部第 4 个字节的 17 改成 6（TCP 协议号）。
* **紧急指针**
  占 2 字节。紧急指针仅在 URG = 1 时才有意义，它指出本报文段中**紧急数据的字节数**（紧急数据结束后就是普通数据，也就指出了紧急数据末尾在报文段中的位置）。
* **选项**
  长度可变，最多 40 字节。
  * 最大报文段长度 MSS
    MSS 是每个 TCP 报文段中数据字段的最大长度。MSS 应设置为在 IP 层传输时不需要分片的最大长度，以取得尽可能高的传输效率。
    若主机未填写这一项，MSS 默认值为 536 字节长。
  * 窗口扩大选项
    对有些信道而言（如传播时延和带宽都很大的卫星信道），窗口字段 2 字节的大小不够用，为获得高吞吐率需要更大的窗口大小。
  * 时间戳选项
    用于计算往返时间 RTT，以及用于防止序号绕回。
  * 选择确认选项
    后文有详述。

### 5. TCP 可靠传输实现

以下叙述都假定数据传输只在一个方向上进行，即 A 发送数据，B 给出确认。

#### （1）以字节为单位的滑动窗口

##### ① 发送窗口

![](http://oxglnwe1z.bkt.clouddn.com/17-12-23/48717505.jpg)

A 收到 B 发来的确认报文段后，根据**（接收）窗口值**和**确认号**两个数据来构造自己的发送窗口，A 的发送窗口决不能超过 B 的接收窗口，此外发送窗口还受到拥塞程度的影响。

* 在没有收到 B 的确认的情况下，A 可以把窗口内的数据都发送出去。
* 凡是已发送但未收到确认的字节，都必须暂时保存，以便在超时重传时使用。

发送窗口的位置由窗口前沿和后沿共同确定，但描述一个发送窗口需要 3 个指针：$P_1$，$P_2$，$P_3$，指针都指向字节的序号。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-24/90548740.jpg)

* 小于 $P_1$：已发送已确认
* 大于 $P_3$：不允许发送
* $P_3-P_1$：A 的发送窗口
* $P_2-P_1$：已发送但尚未收到确认的字节数
* $P_3-P_2$：允许发送但当前尚未发送的字节数

##### ② 接收窗口

![](http://oxglnwe1z.bkt.clouddn.com/17-12-24/40323339.jpg)

B 只能对按序收到的数据中的最高序号给出确认。

图中，B 收到了序号为 31~33 的数据，就把数据交付主机，然后删除这些数据，把接收窗口向前移动 3 个序号，同时给 A 发送确认。即使 B 还收到了序号为 37，38 和 40 的数据，但由于并非按序到达，只能先暂存在接收窗口中，不能发送确认。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-24/73200449.jpg)

只要 A 收到确认号落在发送窗口内，A 就可以使发送窗口向前滑动，并发送新的数据。

如果 B 发送的后续确认都滞留在网络中，就会导致 A 认为 B 还没有收到数据，超时计时器到期后，A 会立即重传数据，并重新设置超时计时器。

##### ③ 窗口与缓存

![](http://oxglnwe1z.bkt.clouddn.com/17-12-24/37568843.jpg)

缓存空间和序号空间都是有限的、循环使用的。

* 发送缓存用于存放：
  * 发送应用程序传送给发送方 TCP 准备发送的数据。
  * TCP 已发送出但尚未收到确认的数据。
* 接收缓存用于存放：
  * 按序到达的、尚未被接收应用程序读取的数据。
  * 未按序到达的数据。

还需注意以下情况：

* 同一时刻，A 的发送窗口并不总是和 B 的接收窗口一样大，原因是存在滞后，以及需要进行拥塞控制。
* TCP 通常把不按序到达的数据临时存放在接收窗口中，等字节流中缺少的字节收到后，再按序交付上层应用进程。
* 为了减小传输开销，接收方有**累积确认**功能，但不应过分推迟发送，否则会导致发送方不必要的重传。TCP 标准规定，确认推迟时间不超过 0.5 秒，若收到一连串具有最大长度的报文段，必须每隔一个报文段就发送一个确认。
* TCP 是全双工通信，接收方可以在自己有数据发送时**捎带确认**，但这种情况很少。

#### （2）重传时间的选择

超时重传时间 RTO (Retransmission Time-Out) 的选择是 TCP 最复杂的问题之一。

TCP 下层是互联网环境，报文段可能只经过一个高速率的局域网，也可能经过多个低速率网络，且每个 IP 数据报选择的路由还可能不同。

若重传时间太短，会引起很多报文段不必要的重传，使网络负荷增大。若重传时间太长，则导致网络空闲时间增大，降低传输效率。

TCP 采用一种自适应算法。首先记录一个报文段**发出的时间**和**收到确认的时间**，两个时间的差就是**报文段往返时间 RTT**。

TCP 用所有 RTT 样本计算一个加权平均往返时间 ${RTT}_S$（又称平滑往返时间，S 表示 Smoothed），第一次测量到 RTT 样本时，${RTT}_S$ 值就取为所测量到的 RTT 样本值，但之后每测量到一个新的 RTT 样本，就重新计算一次 ${RTT}_S$：
$$
new \,{RTT}_S=(1-\alpha)\times(old\,{RTT}_S)+\alpha\times(new\,RTT)
$$
上式中，$0\le\alpha<1$，$\alpha$ 越接近 0，${RTT}_S$ 变化越平滑。推荐标准 RFC 6298 中，**$\alpha$ 值为 0.125**。

超时计时器设置的 RTO 应略大于 ${RTT}_S$，且应将对均值的偏差考虑在内，根据 RFC 6298：
$$
RTO={RTT}_S+4\times{RTT}_D
$$
${RTT}_D$ 是 RTT 的偏差的加权平均值，第一次测量时，${RTT}_D$ 值取为测量到的 RTT 样本值的一半，在以后的测量中，使用下式计算加权平均的 ${RTT}_D$：
$$
new\,{RTT}_D=(1-\beta)\times(old\,{RTT}_D)+\beta\times|{RTT}_S-new\,RTT|
$$
$\beta$ 是个小于 1 的系数，**推荐值是 0.25**。

此外，往返时间的测量，具有相当大的复杂性。发送出一个报文段，设定的重传时间到了还没有收到确认，就要重传报文段，一段时间后收到确认报文段。如何判定**此确认报文段是对先发送的报文段的确认，还是对后来重传的报文段的确认？**

![](http://oxglnwe1z.bkt.clouddn.com/17-12-24/27465310.jpg)

如果错误判定确认报文段的归属，就会导致计算出的 RTO 偏大或偏小，错误的 RTO 设定又会引发连锁反应。

为解决这个问题，Karn 提出一个算法：**在计算加权平均 ${RTT}_S$ 时，只要报文段重传了，就不采用其往返时间样本**。这样就筛除了无效的往返时间样本，使计算结果更加合理。

但这种方法有缺点，如果报文段时延突然增大很多，导致在原来的 RTO 内无法收到确认报文段，那么 RTO 就无法更新了。

因此要对 Karn 算法做出修改：**每报文段每重传一次，就把 RTO 增大一些（通常是翻倍），当不再发生重传时，才按公式计算 RTO**。

#### （3）选择确认 SACK

若接收方收到的报文段中间只缺少一些序号的数据，接收方就先收下这些数据，再把信息准确告诉发送方，使发送方不要再重复发送已收到的数据，这就是**选择确认**（Selective ACK）的作用。

但由于 TCP 首部空间有限，一个边界指针就占 4 个字节（序号有 32 位），选项中最多也只能容纳 4 个字节块的确认。

SACK 文档没有具体指明发送方应当怎样响应，因此大多数实现还是重传所有未被确认的数据块。

### 6. TCP 流量控制

**流量控制**（flow control）就是让发送方的发送速率不要太快，要让接收方来得及接收。

#### （1）利用滑动窗口实现流量控制

如图所示，主要原理就是**发送方的发送窗口不能超过接收方给出的接收窗口的数值**。

![滑动窗口流量控制](http://oxglnwe1z.bkt.clouddn.com/17-12-24/91003954.jpg)

但有一种特殊情况需要注意：B 向 A 发送零窗口报文段后不久，B 的接收缓存又有了一些存储空间，但 B 向 A 发送的 rwnd = 400 的报文段在传送过程中丢失了。A 一直等待 B 发送的非零窗口的通知，B 也一直等待 A 发送的数据，如果没有其他措施，这种互相等待的死锁局面将一直持续下去。

为解决这个问题，TCP 为每个连接设置了一个**持续计时器**（persistence timer），只要连接的一方收到对方的零窗口通知，就启动持续计时器。持续计时器设置的时间一到期，就发送一个零窗口探测报文段（TCP 规定，即使设置为零窗口，也必须接收零窗口探测报文段、确认报文段和携带紧急数据的报文段），对方就在确认时给出新的窗口值。

如果窗口不是零，死锁的僵局就打破了；如果窗口还是零，就重置持续计时器，继续等待或发送探测报文段。

#### （2）TCP 传输效率控制

三种控制 TCP 报文段发送时间的机制：

* 维持一个变量，它等于最大报文段长度 MSS。只要缓存中存放的数据达到 MSS 字节，就组装成一个 TCP 报文段发送出去。
* 由发送方进程指明要求发送报文段，这是 TCP 支持的推送（push）操作。
* 发送方的一个计时器期限到了，就把已有的缓存数据（不超过 MSS）装入报文段发送出去。

（未完待续）

### 7. TCP 拥塞控制

####（1）定义

计算机网络中的链路容量（即带宽）、交换结点的缓存和处理机等，都是**网络资源**。在某段时间，若网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就会变坏，整个网络**吞吐量将随输入负载的增大而下降**。这种情况被称为**拥塞**。
$$
\sum{对资源的需求}>可用资源
$$
拥塞是一个十分复杂的、多变量的系统问题。简单地增加一部分资源，非但不一定能解决问题，还可能把瓶颈转移到其他地方，引发新的问题，使网络性能更差。问题的实质是**系统的各部分不匹配**，只有所有部分都平衡了，问题才会解决。

拥塞常常**趋于恶化**（马太效应）。如果路由器没有足够的缓存空间，它就会丢弃一些新到的分组，这会导致发送方反复重传分组，引起更多分组流入网络被丢弃，加剧整个网络的拥塞。

#### （2）拥塞控制与流量控制的区别

拥塞控制是一个**全局性**的过程，涉及到网络中的所有资源，拥塞控制就是要防止过多数据注入到网络中，以避免网络中的路由器或链路过载。拥塞控制的前提就是**网络能承受现有的网络负荷**。

流量控制往往指点对点通信量的控制，是个**端到端问题**（接收端控制发送端）。流量控制就是抑制发送端发送数据的速率，以便接收端来得及接收。

#### （3）拥塞控制原理

下图横坐标为**输入负载**（offered load），代表单位时间内输入给网络的分组数目。纵坐标为**吞吐量**，代表单位时间内从网络输出的分组数目。

![拥塞控制原理](http://oxglnwe1z.bkt.clouddn.com/17-12-24/98228292.jpg)

* 对于**理想的拥塞控制**：在吞吐量饱和之前，网络吞吐量应等于输入负载，呈 $45^\circ$ 斜线；但当输入负载超过某一限度时，由于网络资源受限，吞吐量饱和而保持为水平线，这表明输入的某些分组被丢弃了。
* 对于**实际网络**：随输入负载的增大，吞吐量的增长速率逐渐减小，这表明吞吐量还未饱和时，就已经有一部分输入分组被丢弃了。当吞吐量明显小于输入负载时，网络就进入了**轻度拥塞**状态。当负载到达某一数值时，吞吐量反而随负载增大而下降，这时网络就进入**拥塞状态**。随着负载继续增大到某一数值，吞吐量下降为零，网络无法工作，就称为**死锁**。

从原理上说，拥塞控制就是寻找使不等式不成立的条件，也就是要么开源（增加可用资源），要么节流（减少对资源的需求）。

但实践证明，拥塞控制是很难设计的，因为它是一个复杂的**动态问题**，拥塞控制本身都可能造成系统的性能恶化。这种系统问题需要从控制理论的角度来研究，大体上看，又可以分为**开环控制**和**闭环控制**。

* 开环控制
  设计网络时事先将有关拥塞的问题考虑周到，一旦系统运行起来，就不再中途改正了。
* 闭环控制
  1. **监测**网络系统的各项指标，以发现拥塞发生在何时何地。
     具体指标有被丢弃分组的百分比、平均队列长度、超时重传的分组数。平均分组时延、分组时延标准差等。
  2. 把拥塞**信息传送**到可采取行动的地方。
  3. **调整**网络系统的运行以解决出现的问题。

#### （4）TCP 拥塞控制方法

TCP 使用四种算法进行拥塞控制：**慢开始**（slow-start）、**拥塞避免**（congestion avoidance）、**快重传**（fast retransmit）、**快恢复**（fast recovery）。只有前两种算法是 TCP 协议明确规定的。

以下讨论假定：

* 数据单方向传送，接收方只发送确认报文。
* 接收方有足够大的缓存空间，因此发送窗口大小只由拥塞程度决定。

下面讨论的都是基于窗口的拥塞控制。发送方维持一个叫做**拥塞窗口 cwnd** 的状态变量。拥塞窗口取决于网络拥塞程度，动态地变化。发送方让自己的发送窗口等于拥塞窗口（实际发送窗口大小等于拥塞窗口和接收窗口两者的最小值）。

发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率：

* 只要网络无拥塞，拥塞窗口就再增大一些，以提高网络利用率。
* 一旦网络出现拥塞，就把拥塞窗口减小一些，以减少注入网络的分组数。

其中，**判断拥塞的依据就是出现了超时**（现在线路传输质量很好，因传输出差错的概率很小，可以忽略）。

##### ① 慢开始算法

主机开始发送数据时，不清楚网络负荷情况，如果立即注入数据字节，可能引起拥塞。因此，最好**由小到大逐渐增大拥塞窗口**。

RFC 5681 把**初始拥塞窗口**设置为不超过 2 至 4 个发送方最大报文段 SMSS（Sender Maximum Segment Size）的数值，具体如下：

* 若 SMSS 大于 2190 字节，则设置 cwnd = 2 × SMSS 字节，且不得超过 2 个报文段。
* 若 SMSS 介于 1095 字节和 2190 字节之间，则设置 cwnd = 3 × SMSS 字节，且不得超过 3 个报文段。
* 若 SMSS 小于等于 1095 字节，则设置 cwnd = 4 × SMSS 字节，且不得超过 4 个报文段。

每收到一个对新报文段的确认后，可把拥塞窗口增加最多一个 SMSS 的数值。
$$
cwnd\,每次增加量=min(N,{SMSS})
$$
其中，N 是原先未被确认的、但现在被刚收到的确认报文段所确认的字节数。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-24/27184452.jpg)

为叙述方便起见，用报文段个数作为窗口大小的单位，可以看出，**每经过一个传输轮次，拥塞窗口 cwnd 就加倍**。一个传输轮次经历的时间就是往返时间 RTT（并非恒定），例如，cwnd 的大小是 4 个报文段，这时的往返时间就是发送方连续发送 4 个报文段，并收到这 4 个报文段的确认，所总共经历的时间。

上图还有一些不准确的地方。现实情况下，发送方只要收到一个对新报文段的确认，其拥塞窗口就立即加 1，并可以立即发送新的报文段，而不必等该轮所有确认都收到后才发送新的报文段。

为防止 cwnd 无限增大引起拥塞，还需要设置一个**慢开始门限 ssthresh 状态变量**，用法如下：

* 当 cwnd < ssthresh 时，使用慢开始算法。
* 当 cwnd > ssthresh 时，使用拥塞避免算法。
* 当 cwnd = ssthresh 时，两种算法都可以。

##### ② 拥塞避免算法

拥塞避免算法的思路是让 cwnd 缓慢增大，即**每经过一个往返时间 RTT 就把发送方的拥塞窗口加 1**。不同于慢开始阶段的成倍增长，这时的 cwnd 按线性规律缓慢增长。

无论是慢开始算法还是拥塞避免算法，只要发送方判断网络出现拥塞，就**把 ssthresh 设置为出现拥塞时发送方窗口值的一半（但不能小于 2），然后把 cwnd 重新设置为 1，执行慢开始算法**。这样做是为了迅速减少主机发送到网络中的分组数，让路由器有足够时间处理完队列中积压的分组。

“乘法减小”和“加法增大”合起来常称为 AIMD 算法。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-25/80809390.jpg)

##### ③ 快重传算法

快重传算法要求**接收方每收到一个失序的报文段就立即发出重复确认**而不要等待自己发送数据才进行捎带确认。

**发送方只要一连收到三个重复确认就应当立即重传丢弃的报文段**  $M_3$，不必等待重传计时器到期。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-25/90264207.jpg)

采用快重传算法可以使整个网络吞吐量提高约 20%。

##### ④ 快恢复算法

快恢复算法与快重传算法配合使用，有两大要点：

* 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把 ssthresh 减半，以预防网络发生拥塞。请注意，接下来不执行慢开始算法。
* 直接设置 cwnd = ssthresh，并开始执行拥塞避免算法。

### 8. TCP 连接管理

TCP 是面向连接的协议。连接的声明周期有三个阶段：**连接建立**、**数据传送**、**连接释放**。连接管理就是让连接的**建立和释放**能够正常进行。

#### （1）TCP 连接建立

TCP 连接建立过程中要解决三个问题：

* 要使每一方能够确知对方的存在。
* 要允许双方协商一些参数（如最大窗口值、是否使用各种选项等）。
* 能够对运输实体资源进行分配。

TCP 连接建立采用**客户服务器方式**。主动发起连接建立的应用进程叫做**客户**（client），被动等待连接建立的应用进程叫做**服务器**（server）。

##### ① 三次握手

TCP 建立连接的过程称为**握手**。握手需要在客户和服务器之间交换三个 TCP 报文段，这就是大名鼎鼎的**“三次握手”**（但实质上是一次握手过程中交换了三次报文）。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-25/29604886.jpg)

这里假设 A 运行 TCP 客户程序，B 运行 TCP 服务器程序。由 A 主动打开连接，B 被动打开连接。

刚开始两端 TCP 进程都处于 **CLOSED 状态**。为接受连接，两边还要创建**传输控制块 TCB**（Transmission Control Block），其中存储了 TCP 连接表、指向缓存的指针等信息，之后就处于 **LISTEN 状态**了。

* 第一步，A 向 B 发送 SYN 报文段。
  SYN 报文段首部中的同步位 SYN = 1，同时还要随机选择一个初始序号 seq  = x 放到序号字段中。该报文段不能携带数据，但要消耗一个序号。
  这时，A 进入 **SYN-SENT（同步已发送）状态**。

* 第二步，B 收到 SYN 报文段后，如同意建立连接，则分配并初始化连接变量和缓存，并向 A 发送 SYNACK 报文段作为确认。

  SYNACK 报文段中 SYN 位和 ACK 位都置 1，确认号 ack = x + 1，同时还要选择服务器自己的初始序号 seq = y。该报文段同样不能携带数据，但也要消耗一个序号。
  此后，B 进入 **SYN-RCVD（同步收到）状态**。

* 第三步，A 收到 SYNACK 报文段后，也要给该连接分配缓存和变量，并向 B 发出 ACK 报文段进行确认。
  ACK 报文段中 SYN 位置 0（连接已建立），ACK 位置 1，确认号 ack = y + 1，序号 seq = x + 1。ACK 报文段可以携带数据，但如果不携带数据则不消耗序号。
  这时，A 进入 **ESTABLISHED 状态**。当 B 收到 A 的确认后，也进入 ESTABLISHED 状态。

为什么 A 最后还要发送一次确认？主要是为了防止已失效的 SYN 报文段突然又传送到了 B，让 B 错误地以为新连接建立了，一直等待 A 发来数据，白白浪费资源。

##### ② SYN 洪泛攻击

三次握手的实现方式有个漏洞，那就是服务器为了响应收到的 SYN，分配并初始化连接变量和缓存，然后发送一个 SYNACK 进行确认，并等待客户端的 ACK 报文段。如果客户端一直不发送 ACK 来完成第三步，过一段时间服务器才收回半开的连接并回收资源。

这种 TCP 协议为爷爷辈的 DoS 攻击 **SYN 洪泛攻击**（SYN flood attack）提供了环境：攻击者**大量发送 TCP SYN 报文段，而不完成第三次握手的步骤**。服务器不断为这种半开连接分配资源（但从未使用），导致服务器资源迅速消耗殆尽。

抵御此攻击的常用方法是使用 **SYN cookie**：

* 当服务器收到一个 SYN 报文段时，不会为它生成一个半开连接。而是生成一个初始 TCP 序列号 “cookie”，它是报文段源和目的 IP 地址与端口号以及密钥共同构成的一个散列函数。服务器把 “cookie” 放到 SYNACK 报文段里发送出去，而不会记忆任何状态信息。
* 如果客户是合法的，它将返回一个 ACK 报文段，其确认字段等于 cookie 值加 1。服务器收到报文段后，就再次运行散列函数，如果函数的结果加 1 等于确认号，就认为它是合法的。接下来服务器就生成一个具有套接字的全开连接。
* 如果客户不返回 ACK 报文段，初始的 SYN 也不会对服务器产生危害，因为服务器并没有为它分配资源。

#### （2）TCP 连接释放

##### ① 四次握手

数据通信结束后（但还处于 ESTABLISHED 状态），通信双方都可以释放连接。假设 A 决定主动关闭 TCP 连接：

![](http://oxglnwe1z.bkt.clouddn.com/17-12-25/99787691.jpg)

* 第一步，A 发送连接释放报文段。
  报文段首部 FIN 位置 1，序号 seq = u，它等于前面已传送的数据的最后一个字节的序号加 1。FIN 报文段无论如何都会消耗一个序号。
  此时，A 进入 **FIN-WAIT-1（终止等待 1）状态**，等待 B 的确认。
* 第二步，B 收到连接释放报文段即发出确认。
  报文段 ACK 位置 1，确认号 ack = u + 1，该报文段自身序号是 v，等于 B 之前传送过的数据的最后一个字节的序号加 1。
  之后，B 进入 **CLOSE-WAIT（关闭等待）状态**。TCP 服务器进程通知高层应用进程，从 A 到 B 的连接已释放，但从 B 到 A 的连接并未关闭，整个 TCP 连接处于半关闭（half-close）状态。
* 第三步，A 收到来自 B 的确认。
  此时，A 进入 **FIN-WAIT-2（终止等待 2）状态**。继续等待 B 发出的连接释放报文段。
* 第四步，若 B 也没有数据要向 A 发送，应用进程就通知 TCP 释放连接，B 发出连接释放报文段。
  报文段首部 FIN 位和 ACK 位都置 1，序号 seq = w（半关闭状态 B 可能又发送过一些数据），确认号 ack = u + 1 和之前一样。
  此时，B 进入 **LAST-ACK（最后确认）状态**。
* 第五步，A 收到 B 的连接释放报文段并发出确认。
  报文段 ACK 位置 1，确认号 ack = w + 1，序号 seq = u + 1。
  之后，A 进入 **TIME-WAIT（时间等待）状态**。但此时 TCP 连接还没有释放掉，必须经过时间等待计数器（TIME-WAIT timer）设置的时间 2MSL 后，A 才进入 **CLOSED 状态**，之后才能建立新连接。
  而 B 一旦收到 A 发出的确认，就进入 CLOSED 状态。

最长报文段寿命 MSL（Maximum Segment Lifetime）在工程上通常设置为 2 分钟及以下。之所以要等待 2MSL，是因为：

* 如果最后一个 ACK 报文段丢失，B 会超时重传 FIN + ACK 报文段，这样 A 就能在 2MSL 时间内收到重传的报文段，再次发出确认并重启 2MSL 计时器。如果 A 不等待，B 就有可能无法正常进入 CLOSED 状态。
* 可以防止已失效的连接请求报文段再出现于本连接中，经过2MSL 后，就可以使本连接持续时间内产生的所有报文段都从网络中消失。

##### ② 异常终止

除了正常连接释放，还应考虑到意外终止，比如客户端主机突然出故障。

这时可以使用**保活计数器**（keepalive timer）让服务器不必白白等下去。服务器每收到一次客户的数据，就重新设置保活计数器，时间通常是 2 小时。若 2 小时没有收到客户数据，就每隔 75 秒发送一个探测报文段，若连续 10 个探测报文段无响应，服务器就认为客户端出了故障，于是关闭连接。

#### （3）TCP 有限状态机

如图所示，粗实线箭头表示对客户进程的正常变迁，粗虚线箭头表示对服务器进程的正常变迁，细线箭头表示异常变迁。

![](http://oxglnwe1z.bkt.clouddn.com/17-12-25/44622567.jpg)





